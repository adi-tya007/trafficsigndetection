# -*- coding: utf-8 -*-
"""Trafficsign_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10gZDddCk4IbEnG6NY4xe0SGJKFzZ_Xzz
"""

from google.colab import files
uploaded = files.upload()  # Upload ZIP file from your PC

import zipfile
import os

# Unzip the file
zip_path = "TrafficSign_Dataset.zip"  # Use the exact filename
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("TrafficSign_Dataset")

import zipfile
import os

# Unzip the uploaded dataset
zip_path = "TrafficSign_Dataset.zip"  # Use the correct uploaded filename
extract_path = "TrafficSign_Dataset"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall()

# Check if dataset is extracted correctly
print("Top-level contents:", os.listdir(extract_path))
print("Subfolders in 'Images':", os.listdir(os.path.join(extract_path, "Images")))

dataset_path = "Images"

import os
import numpy as np
import cv2
import pickle
from tqdm import tqdm
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint
from sklearn.model_selection import train_test_split

# Load dataset function
def load_dataset(dataset_path):
    images = []
    labels = []

    label_dict = {name: idx for idx, name in enumerate(sorted(os.listdir(dataset_path)))}

    for folder in os.listdir(dataset_path):
        folder_path = os.path.join(dataset_path, folder)
        if not os.path.isdir(folder_path):
            continue
        label = label_dict[folder]

        for img_name in tqdm(os.listdir(folder_path), desc=f"Loading {folder}"):
            img_path = os.path.join(folder_path, img_name)
            img = cv2.imread(img_path)
            if img is None:
                continue
            img = cv2.resize(img, (64, 64))
            images.append(img)
            labels.append(label)

    X = np.array(images, dtype="float32") / 255.0
    y = to_categorical(np.array(labels), num_classes=len(label_dict))

    return X, y, label_dict

# Define model
def build_model(num_classes):
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(64, 64, 3)),
        BatchNormalization(),
        MaxPooling2D(2, 2),
        Dropout(0.25),

        Conv2D(64, (3, 3), activation='relu', padding='same'),
        BatchNormalization(),
        MaxPooling2D(2, 2),
        Dropout(0.25),

        Conv2D(128, (3, 3), activation='relu', padding='same'),
        BatchNormalization(),
        MaxPooling2D(2, 2),
        Dropout(0.25),

        Flatten(),
        Dense(256, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])
    return model

# Train function
def train_model(dataset_path):
    X, y, label_dict = load_dataset(dataset_path)
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

    model = build_model(len(label_dict))
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    callbacks = [
        ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, verbose=1),
        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),
        ModelCheckpoint("best_traffic_model.keras", monitor='val_accuracy', save_best_only=True)
    ]

    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=30, batch_size=64, callbacks=callbacks)

    loss, acc = model.evaluate(X_val, y_val)
    print(f"\nâœ… Final Validation Accuracy: {acc * 100:.2f}%")

    # Save model and label dictionary
    model.save("traffic_sign_cnn.keras")
    with open("label_dict.pkl", "wb") as f:
        pickle.dump(label_dict, f)

# Run training
dataset_path = "TrafficSign_Dataset/Images"  # Already extracted path
train_model(dataset_path)

from google.colab import files
files.download("traffic_sign_cnn.keras")
files.download("label_dict.pkl")